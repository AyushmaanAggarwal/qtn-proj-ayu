{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbce373-a558-4506-9884-047ba59b466b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9effaad3-4ead-4fec-88c3-0e0e8e8efa3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0229288-c8bc-4759-9b22-491cdd981c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(lst, max_val):\n",
    "    return np.array([val/max_val for val in lst])\n",
    "\n",
    "def denorm(lst, max_val):\n",
    "    return np.array([val*max_val for val in lst])\n",
    "\n",
    "def progress_bar(percent):\n",
    "    bar_len = 20\n",
    "    n = int(percent*bar_len)#int(percent*100//bar_len)\n",
    "    p = int(percent*100//1)\n",
    "    print(\"\\r[\"+(\"=\"*n + \" \"*int(bar_len-n))+\"] \"+str(p)+\"%\",end=\" \")\n",
    "\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0fe02-d043-44f6-9bab-e222c4fcbd52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random Seeds and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c0b7ce-6880-48fa-bdf3-3cda0e6d0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed value: \n",
    "keras.utils.set_random_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9285a3c7-9aae-49c2-a121-8b25282f433d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/pickle/data\", 'rb') as file:\n",
    "    var = pickle.load(file=file)\n",
    "    max_y            = var[\"max_y\"]\n",
    "    train_x_data     = var[\"train_x_data\"][:]\n",
    "    train_y_data     = var[\"train_y_data\"][:]\n",
    "    test_time_sorted = var[\"test_time_sorted\"][:]\n",
    "    test_x_sorted    = var[\"test_x_sorted\"][:]\n",
    "    test_y_sorted    = var[\"test_y_sorted\"][:]\n",
    "    test_y_sorted_ed = var[\"test_y_sorted_ed\"][:]\n",
    "    freq             = var[\"freq\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5533a4f-594b-4747-9531-38a35279bfa7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09063db6-4219-4373-be81-d9a4ae3ca9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 13:55:10.823957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-27 13:55:10.823971: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-27 13:55:10.823983: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ayu): /proc/driver/nvidia/version does not exist\n",
      "2022-06-27 13:55:10.824175: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(8, kernel_size=3, activation='relu', input_shape=(96, 1)))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(8, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df5a78-e1e8-4d31-b491-3d65b8ed4898",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9f3e26-9a88-406b-8c28-a29a08dcfd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.mean_absolute_percentage_error,#lambda y_true, y_pred: keras.losses.huber(y_true, y_pred, .0015), \n",
    "   optimizer = keras.optimizers.Adam(), metrics = ['MeanAbsolutePercentageError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b1565c-7484-4539-b28e-45826010556e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12800/12800 - 12s - loss: 4.5411 - mean_absolute_percentage_error: 4.5411 - val_loss: 2.5863 - val_mean_absolute_percentage_error: 2.5863 - 12s/epoch - 936us/step\n",
      "Epoch 2/20\n",
      "12800/12800 - 13s - loss: 2.0852 - mean_absolute_percentage_error: 2.0852 - val_loss: 1.8537 - val_mean_absolute_percentage_error: 1.8537 - 13s/epoch - 1ms/step\n",
      "Epoch 3/20\n",
      "12800/12800 - 12s - loss: 1.6548 - mean_absolute_percentage_error: 1.6548 - val_loss: 1.5483 - val_mean_absolute_percentage_error: 1.5483 - 12s/epoch - 943us/step\n",
      "Epoch 4/20\n",
      "12800/12800 - 12s - loss: 1.5063 - mean_absolute_percentage_error: 1.5063 - val_loss: 1.4124 - val_mean_absolute_percentage_error: 1.4124 - 12s/epoch - 947us/step\n",
      "Epoch 5/20\n",
      "12800/12800 - 12s - loss: 1.4391 - mean_absolute_percentage_error: 1.4391 - val_loss: 1.4211 - val_mean_absolute_percentage_error: 1.4211 - 12s/epoch - 938us/step\n",
      "Epoch 6/20\n",
      "12800/12800 - 12s - loss: 1.3784 - mean_absolute_percentage_error: 1.3784 - val_loss: 1.5113 - val_mean_absolute_percentage_error: 1.5113 - 12s/epoch - 962us/step\n",
      "Epoch 7/20\n",
      "12800/12800 - 12s - loss: 1.3384 - mean_absolute_percentage_error: 1.3384 - val_loss: 1.3095 - val_mean_absolute_percentage_error: 1.3095 - 12s/epoch - 959us/step\n",
      "Epoch 8/20\n",
      "12800/12800 - 12s - loss: 1.3021 - mean_absolute_percentage_error: 1.3021 - val_loss: 1.2457 - val_mean_absolute_percentage_error: 1.2457 - 12s/epoch - 938us/step\n",
      "Epoch 9/20\n",
      "12800/12800 - 13s - loss: 1.2668 - mean_absolute_percentage_error: 1.2668 - val_loss: 1.5195 - val_mean_absolute_percentage_error: 1.5195 - 13s/epoch - 999us/step\n",
      "Epoch 10/20\n",
      "12800/12800 - 12s - loss: 1.2376 - mean_absolute_percentage_error: 1.2376 - val_loss: 1.1729 - val_mean_absolute_percentage_error: 1.1729 - 12s/epoch - 956us/step\n",
      "Epoch 11/20\n",
      "12800/12800 - 12s - loss: 1.2246 - mean_absolute_percentage_error: 1.2246 - val_loss: 1.1282 - val_mean_absolute_percentage_error: 1.1282 - 12s/epoch - 942us/step\n",
      "Epoch 12/20\n",
      "12800/12800 - 13s - loss: 1.1866 - mean_absolute_percentage_error: 1.1866 - val_loss: 1.3605 - val_mean_absolute_percentage_error: 1.3605 - 13s/epoch - 993us/step\n",
      "Epoch 13/20\n",
      "12800/12800 - 12s - loss: 1.1767 - mean_absolute_percentage_error: 1.1767 - val_loss: 1.1181 - val_mean_absolute_percentage_error: 1.1181 - 12s/epoch - 959us/step\n",
      "Epoch 14/20\n",
      "12800/12800 - 12s - loss: 1.1589 - mean_absolute_percentage_error: 1.1589 - val_loss: 1.1070 - val_mean_absolute_percentage_error: 1.1070 - 12s/epoch - 956us/step\n",
      "Epoch 15/20\n",
      "12800/12800 - 13s - loss: 1.1490 - mean_absolute_percentage_error: 1.1490 - val_loss: 1.1369 - val_mean_absolute_percentage_error: 1.1369 - 13s/epoch - 991us/step\n",
      "Epoch 16/20\n",
      "12800/12800 - 12s - loss: 1.1341 - mean_absolute_percentage_error: 1.1341 - val_loss: 1.0713 - val_mean_absolute_percentage_error: 1.0713 - 12s/epoch - 962us/step\n",
      "Epoch 17/20\n",
      "12800/12800 - 13s - loss: 1.1063 - mean_absolute_percentage_error: 1.1063 - val_loss: 1.0868 - val_mean_absolute_percentage_error: 1.0868 - 13s/epoch - 982us/step\n",
      "Epoch 18/20\n",
      "12800/12800 - 13s - loss: 1.0786 - mean_absolute_percentage_error: 1.0786 - val_loss: 1.1245 - val_mean_absolute_percentage_error: 1.1245 - 13s/epoch - 980us/step\n",
      "Epoch 19/20\n",
      "12800/12800 - 13s - loss: 1.0822 - mean_absolute_percentage_error: 1.0822 - val_loss: 1.0053 - val_mean_absolute_percentage_error: 1.0053 - 13s/epoch - 1ms/step\n",
      "Epoch 20/20\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 256000 batches). You may need to use the repeat() function when building your dataset.\n",
      "12800/12800 - 4s - loss: 1.0781 - mean_absolute_percentage_error: 1.0781 - val_loss: 1.3007 - val_mean_absolute_percentage_error: 1.3007 - 4s/epoch - 283us/step\n"
     ]
    }
   ],
   "source": [
    "step_num = 12800#int(len(train_y_data)//32)\n",
    "history = model.fit(\n",
    "    x=train_x_data[:], y=train_y_data[:], epochs=20, batch_size=32, steps_per_epoch=step_num,\n",
    "    validation_split=.1, workers=8, use_multiprocessing=True, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e22a012-b1b6-4f4b-b7f6-bf23e4e64bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ml_models/cnn_20220627.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e64ad-5622-4b6d-9e28-15014199ad74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbafc1e8-eb23-4653-b2a6-d714c3d9ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('ml_models/cnn_20220627.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "514b28fc-52da-4a12-b0a7-7167809e8b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520/1520 [==============================] - 1s 589us/step - loss: 1.2884 - mean_absolute_percentage_error: 1.2884\n"
     ]
    }
   ],
   "source": [
    "perf = model.evaluate(test_x_sorted, test_y_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e263ce59-493c-4f87-b496-e0c87694c8c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520/1520 [==============================] - 1s 518us/step\n"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict(test_x_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af51b21-add2-49e8-99db-acc0e35567dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "denorm_test = denorm(test_y_sorted, max_y)\n",
    "denorm_pred = denorm(pred_y, max_y)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6880f09f-d7c4-4869-bc61-0d31c447259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = np.mean(list(map(lambda i: (denorm_test[i]**2)/test_y_sorted_ed[i],\n",
    "               range(len(denorm_test)))))\n",
    "pred_dens = list(map(lambda i: (denorm_pred[i]**2)/constant,\n",
    "               range(len(denorm_pred))))\n",
    "dens = list(map(lambda i: (denorm_test[i]**2)/constant,\n",
    "               range(len(denorm_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de0058b7-d8a6-4641-8f37-659403492917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each predicted value has an error of ±5.8422352063824156e-05% or ±1.5404919583691603 kHz\n",
      "The average predicted value is 25.78584098815918\n",
      "Predicted first value: 19.523935317993164 ±1.5404919583691603 kHz\n",
      "Each predicted electron density has an error of ±0.001296823150357523 cm^-3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.285981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.056863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.114978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.215418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.311369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  48631.000000\n",
       "mean       0.285981\n",
       "std        2.204952\n",
       "min        0.000004\n",
       "25%        0.056863\n",
       "50%        0.114978\n",
       "75%        0.215418\n",
       "max       68.311369"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percent Error\n",
    "lst = list(map(lambda i: abs(denorm_pred[i]-denorm_test[i])/denorm_test[i],\n",
    "               range(len(pred_y))))\n",
    "# Squared Error\n",
    "lst2 = list(map(lambda i: (denorm_pred[i]-denorm_test[i])**2,\n",
    "               range(len(pred_y))))\n",
    "# Error\n",
    "lst3 = list(map(lambda i: (denorm_pred[i]-denorm_test[i]),\n",
    "               range(len(pred_y))))\n",
    "# Electron Density Error\n",
    "lst4 = list(map(lambda i: abs(pred_dens[i]-test_y_sorted_ed[i]),\n",
    "               range(len(pred_y))))\n",
    "error = np.sqrt(sum(lst2)/len(lst2))\n",
    "print(f\"Each predicted value has an error of ±{np.mean(lst)/np.sqrt(len(lst))}% or ±{error} kHz\")\n",
    "print(f\"The average predicted value is {np.mean(denorm_pred)}\")\n",
    "print(f\"Predicted first value: {denorm_pred[0]} ±{error} kHz\")\n",
    "print(f\"Each predicted electron density has an error of ±{np.mean(lst4)/np.sqrt(len(lst4))} cm^-3\")\n",
    "pd.DataFrame(lst4).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e067d1cd-1914-4e02-b720-b057794a9c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dic = {}\n",
    "data_dic[\"Pred_y\"] = denorm_pred\n",
    "data_dic[\"Act_y\"]  = denorm_test\n",
    "data_dic[\"x\"]      = test_x_sorted\n",
    "data_dic[\"res\"]    = lst3\n",
    "with open(\"data/pickle/error_dist\", 'wb') as file:\n",
    "    pickle.dump(data_dic, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6144f27-d6aa-4403-8920-d0d46b6716aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799b104-ffcc-4713-9fc6-9bc3e483c99a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ploting Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea69035-36f6-4cc8-8ef6-4fee405d0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef7797-38f7-4212-930b-b09ae4d6923c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    plt.figure(facecolor='w')\n",
    "    plt.title(\"Validation Performance after each epoch - MAPE\")\n",
    "    plt.plot(history.history[\"mean_absolute_percentage_error\"], label=\"Average Error during Training\")\n",
    "    plt.axhline(perf[1], color='g', label=\"Average Error during Testing\")\n",
    "    plt.xlabel(\"Epoch (80% of total training data)\")\n",
    "    plt.ylabel(\"Average Percent Error (%)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"plots/validation_performance_over_time_mape.png\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cac73-1ed2-45ef-bbe5-63eb99cfef6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    fig, (ax0, ax1) = plt.subplots(1,2, figsize=(6*2,5), facecolor='w')\n",
    "    fig.suptitle(\"Performance of CNN after trainning to match NASA's NN June 1st to 26th 1995\")\n",
    "\n",
    "    ax0.plot(test_time_sorted, denorm_test, label=\"Neural Network(estimated)\",linewidth=2)\n",
    "    ax0.plot(test_time_sorted, denorm_pred, label=\"Convolutional Neural Network - MAPE\",linewidth=2)\n",
    "    ax0.set_title(\"Predicted vs Estimated Plasma Frequency\")\n",
    "    ax0.set_xlabel(\"Epoch Time (s)\")\n",
    "    ax0.set_ylabel(\"Plasma Frequency (kHz)\")\n",
    "    ax0.legend()\n",
    "\n",
    "    res = np.subtract(denorm(pred_y, max_y)[:,0],denorm(test_y_sorted, max_y))\n",
    "    ax1.axhline(0, color='black', linewidth=1, label=\"Reference Line\")\n",
    "    ax1.scatter(test_time_sorted, res, s=3, label=\"y_CNN - y_NN\")\n",
    "    denorm_test = denorm(test_y_sorted, max_y)\n",
    "    for i in range(len(res)):\n",
    "        if denorm_test[i] < 10:\n",
    "            ax1.scatter(test_time_sorted[i], res[i], s=3, color='r')\n",
    "\n",
    "    ax1.set_title(\"Difference between CNN and NN\")\n",
    "    ax1.set_xlabel(\"Epoch Time (s)\")\n",
    "    ax1.set_ylabel(\"Residuals\")\n",
    "    ax1.legend(loc='lower right')\n",
    "\n",
    "    fig.savefig(\"plots/performance_on_test_dataset_mape.png\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b069e-e680-44ba-92e1-d9bb7e1fb47b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    def norm_dist(val, mean=np.mean(lst3), standard_dev=np.std(lst3)):\n",
    "        factor = 1/np.sqrt(2*np.pi*(standard_dev**2))\n",
    "        exp = np.exp(-(val - mean)**2/(2*(standard_dev**2)))\n",
    "        return factor*exp\n",
    "\n",
    "    x = [-2 + i*.1 for i in range(40)]\n",
    "    y = [norm_dist(v)*3000 for v in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714bdc2-7a4e-4801-8644-dd6fbe381107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    fig, ax = plt.subplots(facecolor='w')\n",
    "    ax.hist(lst3, 2000, histtype='bar')\n",
    "    ax.set_xlim(-3,3)\n",
    "    ax.set_title(\"Histogram of residual distribution - MAPE\")\n",
    "    ax.set_xlabel(\"Residual (kHz)\")\n",
    "    ax.set_ylabel(\"Number of Occurences\")\n",
    "    ax.plot(x,y)\n",
    "    plt.savefig(\"plots/hist_mape.png\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc35e30-e6d1-4319-930d-27dccd681a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding all outliers with a frequency error greater than 5\n",
    "data_zip = list(filter(lambda x: abs(x[4])>10, zip(test_time_sorted, test_x_sorted, test_y_sorted, pred_y, res)))\n",
    "test_time_sorted_outliers, test_x_sorted_outliers, test_y_sorted_outliers, pred_y_outliers, res_outliers = list(zip(*data_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3278528-e2b8-4411-866e-f26849015e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_zip2 = list(filter(lambda x: abs(x[4])<.00003, zip(test_time_sorted, test_x_sorted, test_y_sorted, pred_y, res)))\n",
    "# test_time_sorted_best, test_x_sorted_best, test_y_sorted_best, pred_y_best, res_best = list(zip(*data_zip2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2384be-5e55-40c2-b349-562fb1344611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    n = len(res_outliers)\n",
    "    #plt.figure(figsize=(15, 4*n))\n",
    "    fig, ax = plt.subplots(nrows=n, figsize=(9, 3*n), facecolor='w', dpi=200)\n",
    "\n",
    "    for i in range(0, n):    \n",
    "        ax[i].set_ylabel(\"V^2/Hz\")\n",
    "        ax[i].set_xlabel(\"Frequency (kHz)\")\n",
    "        ax[i].xaxis.set_label_coords(.5, -.04)\n",
    "        ax[i].scatter(freq/1000, denorm(test_x_sorted_outliers[i], max_y), s=6,label='WIND data')\n",
    "        ax[i].plot(freq/1000, denorm(test_x_sorted_outliers[i], max_y), markersize=1,label='WIND data')\n",
    "\n",
    "        ax[i].axvline(x=denorm(pred_y_outliers, max_y)[i], color='r', label=\"CNN\")\n",
    "        ax[i].axvline(x=denorm(test_y_sorted_outliers, max_y)[i], color='g', label=\"NASA estimate\")\n",
    "        ax[i].set_xscale('log')\n",
    "        ax[i].set_yscale('log')\n",
    "        ax[i].set_ylim(1, 550)\n",
    "        ax[i].set_xlim(3.5, 275)\n",
    "        ax[i].set_aspect(.2)\n",
    "        ax[i].text(4, 300, f\"Plot #{i+1} - Residual: {np.round(res_outliers[i],2)}\")\n",
    "        ax[i].legend()\n",
    "\n",
    "    fig.suptitle(\"The plot of the spectra with CNN and NASA estimate for plasma frequency\", y=0.888)\n",
    "    plt.savefig(\"plots/outliers.png\", dpi=fig.dpi, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89c338-31fc-41a0-84b9-42f8f332011e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    plt.figure(facecolor='w',figsize=(5,5), dpi=500)\n",
    "    plt.scatter(denorm_pred, denorm_test, s=.1)\n",
    "    plt.xlabel(\"CNN Predicted Plasma Frequency\")\n",
    "    plt.ylabel(\"NASA's NN Predicted Plasma Frequency\")\n",
    "    plt.savefig(\"plots/plot_opposing_predictions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be609c-a131-4da9-97cc-16ea8259c1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    plt.figure(figsize=(8,8), facecolor='w')\n",
    "    plt.hist2d(denorm_pred, denorm_test, bins =[100, 100], density=True,cmap = plt.cm.Greys)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(\"plots/2dhist3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88fcc32-724b-4f8e-99f6-7afa19ed750a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    plt.figure(facecolor='w')\n",
    "\n",
    "    plt.title(\"Histogram of NASA's NN Plasma Frequency Predictions\")\n",
    "    plt.hist(denorm_test, bins=80)\n",
    "\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Number of occurences\")\n",
    "    plt.savefig(\"plots/hist_nasa_nn_plasma_freq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa38812-234e-494e-a1ae-4608b3dc2c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    plt.figure(facecolor='w')\n",
    "\n",
    "    plt.title(\"Histogram of CNN Plasma Frequency Predictions\")\n",
    "    plt.hist(denorm_pred, bins=80)\n",
    "\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Number of occurences\")\n",
    "    plt.savefig(\"plots/hist_cnn_plasma_freq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b55838-b710-4a78-a930-8c4e3562f927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    plt.figure(facecolor='w')\n",
    "    plt.scatter(denorm_test, lst3, s=1)\n",
    "    plt.axhline(0, color='r', linewidth=.5)\n",
    "    plt.xlabel(\"NASA Predicted Plasma Frequency (kHz)\")\n",
    "    plt.ylabel(\"Residuals (kHz)\")\n",
    "    plt.title(\"Comparing change in residuals for each respective plasma frequency\")\n",
    "    plt.savefig(\"plots/residual_and_nasa_plasma_freq\", dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e1229-e351-4270-ad9d-f7e9ed54ce21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plot_figs:\n",
    "    plt.figure(facecolor='w')\n",
    "    plt.hist2d(denorm_test, lst3, bins=[100,100])\n",
    "    plt.xlabel(\"NASA's NN Plasma Frequency (kHz)\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(\"plots/resvsfp1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5101cd8-ce9a-4dfe-b9c6-116ff749e685",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conditional Probablity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480966f6-d5b9-46be-b5f9-af1cc8641ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCPDfig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac99f4-c835-41a7-9e03-d7ab75b2ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotCPDfig:\n",
    "    count = 0\n",
    "    diff = 1.5\n",
    "    int_denorm_test = np.array([int(f) for f in denorm_test])\n",
    "        \n",
    "    dist_error = np.array([[0,0] for _ in range(85)])\n",
    "\n",
    "    for fpe in range(85):\n",
    "        y_list = []\n",
    "        \n",
    "        for findex in np.where(int_denorm_test-fpe<.001)[0]:\n",
    "            f = denorm_test[findex]\n",
    "            indices = np.where(np.abs(denorm_pred-f)<diff)[0]\n",
    "            y_list.extend(np.add(denorm_pred[indices],-f))\n",
    "        \n",
    "        if y_list:\n",
    "            dist_error[fpe] = [np.mean(y_list), np.std(y_list)]\n",
    "\n",
    "        if count%1==0:\n",
    "            progress_bar(count/85)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7115fc3-e224-4824-b194-c55b9b83c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(int_denorm_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83b0c3-2b47-445f-a46a-908fce6597ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotCPDfig:\n",
    "    with open(\"data/pickle/error_dist\", 'rb') as file:\n",
    "        data_dic = pickle.load(file=file)\n",
    "\n",
    "    denorm_pred = np.array(data_dic[\"Pred_y\"])\n",
    "    denorm_test = np.array(data_dic[\"Act_y\"])\n",
    "\n",
    "    del(data_dic)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d587487-483b-45da-9f90-8d769b2a7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotCPDfig:\n",
    "\n",
    "    diff = 1.5\n",
    "    count = 0\n",
    "\n",
    "    hist2dlist = np.array([np.array([0 for _ in range(100)]) for _ in range(85)])\n",
    "\n",
    "    print(\"Started\")\n",
    "    for f in denorm_test:\n",
    "        indices = np.where(np.abs(denorm_pred-f)<diff)[0]\n",
    "        \n",
    "        x = int(f)\n",
    "        y_list = np.multiply(np.add(denorm_pred[indices],1.5-f), 100/3)\n",
    "\n",
    "        for y in y_list:\n",
    "            # count up the x and y coords \n",
    "            hist2dlist[x, int(y)] += 1\n",
    "            \n",
    "        if count%5000==0:\n",
    "            print(count)\n",
    "        count += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2367f07-eb48-4bf1-8fc5-681bb26e38b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plotCPDfig:\n",
    "\n",
    "    cleanhist2dlist = hist2dlist[12:85]\n",
    "\n",
    "    group = 3\n",
    "    hist2dlist3 = []\n",
    "\n",
    "    for i in range(len(cleanhist2dlist)//group):\n",
    "        hist2dlist3.append(np.sum(cleanhist2dlist[group*i:group*i+group], axis=0))\n",
    "\n",
    "    hist2dlist4 = np.array(hist2dlist3)\n",
    "\n",
    "    # for i in range(int(len(hist2dlist4)/2),len(hist2dlist4),2):\n",
    "\n",
    "    #     blur = 2\n",
    "\n",
    "    #     if i+index>len(hist2dlist4):\n",
    "    #         break\n",
    "    #     sum_hist = hist2dlist4[i]\n",
    "    #     for index in range(1,blur):\n",
    "    #         sum_hist += hist2dlist4[i+index]\n",
    "    #     for index in range(blur):\n",
    "    #         hist2dlist3[i+index] = sum_hist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e024098-83c9-469b-adb5-be57e5a6cff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plotCPDfig:\n",
    "\n",
    "    hist2dlist2 = [np.array(row[:]) for row in hist2dlist4]\n",
    "\n",
    "    # for i in range(len(hist2dlist2)):\n",
    "    #     if i>45 and False: # modify False/True if want to disable blur\n",
    "    #         blur = 5#int(i/20+1)\n",
    "    #         for j in range(len(hist2dlist2[i])):\n",
    "    #             section = 5#j//blur \n",
    "    #             #sum_section = sum(hist2dlist[i,section*blur:section*blur+blur])\n",
    "    #             try:\n",
    "    #                 hist2dlist2[i][j] = sum(hist2dlist[i,j:j+blur])\n",
    "    #             except IndexError:\n",
    "    #                 length = len(hist2dlist2[i])\n",
    "    #                 hist2dlist2[i][j] = sum(hist2dlist[i,length-blur:length])\n",
    "\n",
    "    for i in range(len(hist2dlist2)):\n",
    "        min_val = min(hist2dlist2[i])\n",
    "        range_val = max(*hist2dlist2[i], 1) - min(hist2dlist2[i])\n",
    "        hist2dlist2[i] = np.divide(np.subtract(hist2dlist2[i], min_val), range_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135af0ce-40ee-4214-baa6-639842eca9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotCPDfig:\n",
    "\n",
    "    fig, ax = plt.subplots(facecolor='w', figsize=(8,5))\n",
    "\n",
    "    colors = [\"#ffffff\",\"#0000ff\"]\n",
    "    cmap1 = matplotlib.colors.LinearSegmentedColormap.from_list(\"mycmap\", colors)\n",
    "\n",
    "    psm = ax.pcolormesh(np.transpose(hist2dlist2),cmap = cmap1)#, norm=matplotlib.colors.LogNorm())\n",
    "    #ax.set_xlim((12,85))\n",
    "\n",
    "    tickmarks = [-1.5,-1,-.5,0,.5,1]\n",
    "    ax.set_yticks(np.arange(0,100,100/len(tickmarks)))#[0,10,20,30,40,50,60,70,80,90])\n",
    "    ax.set_yticklabels(tickmarks)\n",
    "\n",
    "    tickmarks = np.round(np.array(list(range(1,24,5)))*3+12,1)\n",
    "    ax.set_xticks(np.arange(1,len(hist2dlist2),len(hist2dlist2)/len(tickmarks)))\n",
    "    ax.set_xticklabels(tickmarks)\n",
    "\n",
    "    fig.colorbar(psm)\n",
    "\n",
    "    ax.set_title(\"Conditional Probability Distribution for NASA's NN vs CNN Residuals\")\n",
    "    ax.set_xlabel(\"NASA's NN Plasma Frequency (kHz)\")\n",
    "    ax.set_ylabel(\"Residuals (kHz)\")\n",
    "\n",
    "    plt.savefig(\"plots/conditional_probability_distribution.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a08609-2e12-4525-ad01-ce33af27e4ef",
   "metadata": {},
   "source": [
    "## Pickle Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a51e3-d527-42f8-892e-bc23062e3ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(\"data/pickle/conditional_probx\", 'rb') as file:\n",
    "#     x = pickle.load(file=file)\n",
    "    \n",
    "# with open(\"data/pickle/conditional_proby\", 'rb') as file:\n",
    "#     y = pickle.load(file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dceb8-44ad-4deb-b14a-fa82d63a796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/pickle/conditional_probx\", 'wb') as file:\n",
    "#     pickle.dump(x, file=file)\n",
    "# with open(\"data/pickle/conditional_proby\", 'wb') as file:\n",
    "#     pickle.dump(y, file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
